# -*- coding: utf-8 -*-
"""of Forest Fires Deep Learning Pract.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gRcSfwfgVWbkNYkPdS30YIxea-VUiNHu
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

import tensorflow as tf
from sklearn.model_selection import train_test_split

from keras.models import Sequential
from tensorflow.keras import layers, optimizers
from keras.layers import Dense
from sklearn import svm, datasets

data = pd.read_csv('http://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv')
data

from sklearn.preprocessing import LabelEncoder
encoder = LabelEncoder()
data['month'] = encoder.fit_transform(data['month'])
data['day'] = encoder.fit_transform(data['day'])

data.month.value_counts()

data.day.value_counts()

data.rain.value_counts()

#OHE = pd.get_dummies(data[['day','month','X']], prefix='C')
OHE_day = pd.get_dummies(data.day, prefix='day')
OHE_month = pd.get_dummies(data.month, prefix='month')

OHE_day

OHE_month

from sklearn.preprocessing import MinMaxScaler
def minmaxscal(s,c,cc):
  x = (cc+'mx')
  sc = MinMaxScaler()
  c[x] = sc.fit_transform(s)
  c.pop(cc)
  return c[x]

minmaxscal((data[['area']]), data, ('area'))

minmaxscal((data[['X']]), data, ('X'))
minmaxscal((data[['Y']]), data, ('Y'))
minmaxscal((data[['FFMC']]), data, ('FFMC'))
minmaxscal((data[['DMC']]), data, ('DMC'))

minmaxscal((data[['DC']]), data, ('DC'))
minmaxscal((data[['ISI']]), data, ('ISI'))
minmaxscal((data[['temp']]), data, ('temp'))
minmaxscal((data[['RH']]), data, ('RH'))

minmaxscal((data[['wind']]), data, ('wind'))
minmaxscal((data[['rain']]), data, ('rain'))

data

data = data.drop(['month','day'],axis=1)

new_data = pd.concat([data, OHE_day, OHE_month], axis=1)

new_data

new_data.isnull().any()

new_data = new_data.dropna()

new_data.corr()

#new_data.month_jan.value_counts()

new_data.shape

fitur = new_data.drop(columns='areamx').values
label = new_data['areamx']

X_train, X_test, y_train, y_test = train_test_split(fitur, label, test_size=0.3, random_state=20)



"""# model 1"""

model = Sequential()
model.add(Dense(15, input_dim=29)) 
model.add(Dense(10)) 
model.add(Dense(1, activation = 'linear'))

model.compile(loss="mean_absolute_error", optimizer=optimizers.SGD(learning_rate=0.001), metrics=['accuracy','mae', 'mse'])

model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=32, verbose=1)

"""## hasil nya"""

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='mae')
plt.plot(history.history['val_mae'], label='Valid mae')
plt.legend()
plt.show()

plt.plot(history.history['mse'], label='mse')
plt.plot(history.history['val_mse'], label='Valid mse')
plt.legend()
plt.show()

"""# model 2"""

model = Sequential()
model.add(Dense(29, input_dim=29)) 
model.add(Dense(1, activation = 'linear'))

model.compile(loss="mean_absolute_error", optimizer=optimizers.SGD(learning_rate=0.001), metrics=['accuracy','mae', 'mse'])

model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=32, verbose=1)

"""## hasil nya"""

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='mae')
plt.plot(history.history['val_mae'], label='Valid mae')
plt.legend()
plt.show()

plt.plot(history.history['mse'], label='mse')
plt.plot(history.history['val_mse'], label='Valid mse')
plt.legend()
plt.show()

"""# model 3"""

model = Sequential()
model.add(Dense(29, input_dim=29)) 
model.add(Dense(29, input_dim=29)) 
model.add(Dense(1, activation = 'linear'))

model.compile(loss="mean_absolute_error", optimizer=optimizers.SGD(learning_rate=0.001), metrics=['accuracy','mae', 'mse'])

model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=32, verbose=1)

"""## hasil nya"""

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='mae')
plt.plot(history.history['val_mae'], label='Valid mae')
plt.legend()
plt.show()

plt.plot(history.history['mse'], label='mse')
plt.plot(history.history['val_mse'], label='Valid mse')
plt.legend()
plt.show()

"""# model 4"""

model = Sequential()

model.add(Dense(29, input_dim=29, activation = 'relu')) 
model.add(Dense(1, activation = 'relu'))

model.compile(loss="mean_absolute_error", optimizer=optimizers.SGD(learning_rate=0.001), metrics=['accuracy','mae', 'mse'])

model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=32, verbose=1)

"""## hasil nya"""

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='mae')
plt.plot(history.history['val_mae'], label='Valid mae')
plt.legend()
plt.show()

plt.plot(history.history['mse'], label='mse')
plt.plot(history.history['val_mse'], label='Valid mse')
plt.legend()
plt.show()

"""# model 5"""

model = Sequential()

model.add(Dense(29, input_dim=29, activation = 'linear')) 
model.add(Dense(1, activation = 'linear'))

model.compile(loss="mean_absolute_error", optimizer=optimizers.SGD(learning_rate=0.001), metrics=['accuracy','mae', 'mse'])

model.summary()

history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=32, verbose=1)

"""## hasil nya"""

plt.plot(history.history['loss'], label='loss')
plt.plot(history.history['val_loss'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['accuracy'], label='acc')
plt.plot(history.history['val_accuracy'], label='Valid')
plt.legend()
plt.show()

plt.plot(history.history['mae'], label='mae')
plt.plot(history.history['val_mae'], label='Valid mae')
plt.legend()
plt.show()

plt.plot(history.history['mse'], label='mse')
plt.plot(history.history['val_mse'], label='Valid mse')
plt.legend()
plt.show()

"""# callback"""

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
es = EarlyStopping(monitor=('mae'),mode='min', verbose=1, patience=40)
mc = ModelCheckpoint('best.h5', monitor='mae', mode='min', verbose=1, save_best_only=True)

history3 = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=1000, batch_size=32, verbose=1, callbacks=[es, mc])

"""## hasil callback

"""

plt.plot(history3.history['loss'], label='loss')
plt.plot(history3.history['val_loss'], label='Valid')
plt.legend()
plt.show()

plt.plot(history3.history['accuracy'], label='acc')
plt.plot(history3.history['val_accuracy'], label='Valid')
plt.legend()
plt.show()

plt.plot(history3.history['mae'], label='mae')
plt.plot(history3.history['val_mae'], label='Valid mae')
plt.legend()
plt.show()

plt.plot(history3.history['mse'], label='mse')
plt.plot(history3.history['val_mse'], label='Valid mse')
plt.legend()
plt.show()